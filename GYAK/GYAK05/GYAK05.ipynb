{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "csv_path = \"iris.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class KNNClassifier:\n",
    "\n",
    "    def __init__(self, k:int, test_split_ratio :float) -> None:\n",
    "        self.k = k\n",
    "        self.test_split_ratio = test_split_ratio \n",
    "    \n",
    "\n",
    "    @property\n",
    "    def k_neighbors(self):\n",
    "        return self.k\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_csv ( csv_path :str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        np.random.seed(42)\n",
    "        dataset = np.genfromtxt(csv_path, delimiter=',')\n",
    "        np.random.shuffle(dataset)\n",
    "        x,y = dataset[:,:-1],dataset[:,-1] \n",
    "        return x,y\n",
    "\n",
    "    x,y = load_csv(csv_path)\n",
    "\n",
    "\n",
    "\n",
    "    np.mean(x, axis=0),np.var(x,axis=0)\n",
    "    np.nanmean(x,axis=0),np.nanvar(x,axis=0)\n",
    "    x[np.isnan(x)] = 3.5\n",
    "    (x>10.0).sum(), (x<0.0).sum()\n",
    "    x[np.where(np.logical_or(x>10.0, x<0.0))]\n",
    "\n",
    "    less_than = np.where(x<0.0)\n",
    "    higher_than = np.where(x>10.0)\n",
    "    less_than,higher_than\n",
    "\n",
    "    y = np.delete(y,np.where(x<0.0)[0], axis=0)\n",
    "    y = np.delete(y,np.where(x>10.0)[0], axis=0)\n",
    "\n",
    "    x = np.delete(x,np.where(x<0.0)[0], axis=0)\n",
    "    x = np.delete(x,np.where(x>10.0)[0], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def train_test_split(self, features: np.ndarray, labels: np.ndarray):\n",
    "        test_size = int(len(features)* self.test_split_ratio)\n",
    "        train_size= len(features)-test_size\n",
    "        assert len(features)== test_size + train_size, \"Size mismatch\"\n",
    "\n",
    "        self.x_train, self.y_train = features[:train_size,:] ,labels[:train_size]\n",
    "        self.x_test, self.y_test = features[train_size:,:] ,labels[train_size:]\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    def euclidean(self, element_of_x:np.ndarray)-> np.ndarray:\n",
    "        return np.sqrt(np.sum((self.x_train - element_of_x)**2,axis=1))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def predict( x_test:np.ndarray, self):\n",
    "        labels_pred = []\n",
    "        for x_test_element in x_test:\n",
    "            #tavolsagok meghatarozasa\n",
    "            distances = self.euclidean( x_test_element)\n",
    "            distances = np.array(sorted(zip(distances, self.y_train)))\n",
    "\n",
    "            #leggyakoribb label kiszedÃ©se:\n",
    "            label_pred = mode(distances[:self.k,1],keepdims=False).mode\n",
    "            labels_pred.append(label_pred)\n",
    "\n",
    "        self.y_preds = np.array(labels_pred, dtype=np.int64)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def accuracy(self)-> float:\n",
    "        true_positive = (self.y_test == self.y_preds).sum()\n",
    "        return true_positive / len(self.y_test)*100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def confusion_matrix(self)-> None:\n",
    "        conf_matrix = confusion_matrix(self.y_test, self.y_preds)\n",
    "        return conf_matrix\n",
    "    \n",
    "    \n",
    "   \n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
